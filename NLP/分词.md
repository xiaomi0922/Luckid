#### 1、为什么要分词

（1）分词可缓解一词多义问题

（2）给模型提供了更高维度的feature信息

#### 2、能不能不分词

能，只要模型够大，学习的数据够多，就相当于在模型中内置了分词器，能学习到字之间的关联性和语义信息，比分词+模型效果更好，如bert。

#### 3、中文分词的难点

(1) 歧义问题

(2) 未登录词问题

(3) 分词标准规范问题

#### 4、分词算法

##### (1) 基于词典

贪婪匹配，包括前向最大匹配，后向最大匹配，双向最大匹配

##### (2) 基于统计

###### 2.1 基于语言模型

在切分词图中找到最大可能的路径，给词序列的存在合理性打分的是语言模型

语言模型链式展开简化后就是n-gram语言模型

###### 2.2 基于统计机器学习

HMM  

[如果你跟夕小瑶恋爱了...（上） (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247483976&idx=1&sn=8adcaf7ae04155bf2a8762f950095718&chksm=970c2a9ea07ba3882ba9766660d6e2ee12d21631b48c5e9ccab5a76d7333421ff1197fff280a&scene=21#wechat_redirect)

[如果你跟夕小瑶恋爱了...（下） (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247483991&idx=1&sn=ae339058426e5d66e644f8238aefbb0a&chksm=970c2a81a07ba397a5f5726a1d5cb26bcbcf3eba86bac548ef83ade2a46a4d40c826266ca6a6&scene=21#wechat_redirect)

CRF

[从点到线：逻辑回归到条件随机场 (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484642&idx=1&sn=21f810f91e644f447bb3b5ea2824c613&chksm=970c2c34a07ba522de835d54c4bcaee3316089c24e40c4c9aef33a64772877a2b86a11fd1f5c&scene=21#wechat_redirect)

##### (3) 基于神经网络

###### 3.1 基于Bi-LSTM

[Step-by-step to Transformer：深入解析工作原理（以Pytorch机器翻译为例） (qq.com)](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485185&idx=1&sn=6d33a07715e5c8247b968cceaa7ae322&chksm=970c2fd7a07ba6c146965f91f39c868e78de6753bcecf9b2d629345edf0ff4c0a24cb0268bf5&scene=21#wechat_redirect)

###### 3.2 基于预训练 + 知识蒸馏

#### 5、工具

Jieba 

THULAC

NLPIR-ICTCLAS

LTP

HanLP

Stanford CoreNLP





